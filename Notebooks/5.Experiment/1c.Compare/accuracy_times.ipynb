{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running in vs code\n",
    "# %cd ..\n",
    "# %cd ..\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: run_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from Notebooks.Scripts.post_process import ecdf\n",
    "import Notebooks.Scripts.sampling_utils as sam_util\n",
    "import Notebooks.Scripts.normalization as norm\n",
    "from Notebooks.Scripts import selector_mda\n",
    "import Notebooks.Scripts.Useful as use\n",
    "import Notebooks.Scripts.post_process as post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(sampled, target):\n",
    "    rmse = np.sqrt(np.mean((sampled - target)**2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two = pd.read_csv('fitted_stats/2d_sims.csv')\n",
    "twod_training_target = pd.read_csv('Models/2d_all/damages.csv', index_col = 0)\n",
    "test_set = pd.read_csv('fitted_stats/training_2d.csv')\n",
    "scaler = norm.scaler(df_two)\n",
    "\n",
    "ex_rate = np.loadtxt('fitted_stats/extreme_rate.txt').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = pd.read_csv('Notebooks/4.Active_learning/2d_single/max_min.csv', index_col=0)\n",
    "max_cons = min_max['Max Cons'].item()\n",
    "min_cons = min_max['Min Cons'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_events = pd.read_csv('Notebooks/4.Active_learning/2d_single/Total/sampled_events.csv', index_col = 0)\n",
    "mda_corners = 2**(sampled_events.shape[1] - 1) # damages is included\n",
    "events_resimulate = sampled_events.shape[0] - mda_corners + 1 # + 1 needed as we are including the last sample (stop crit occured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Notebooks/5.Experiment/1b.TGP_accuracy/'\n",
    "\n",
    "rmse_arr = np.zeros((events_resimulate))\n",
    "alm = np.zeros((events_resimulate))\n",
    "ks = np.zeros((events_resimulate))\n",
    "ead = np.zeros((events_resimulate))\n",
    "ead_ground, risk_ground = sam_util.obtain_cons(twod_training_target.values, ex_rate = ex_rate)\n",
    "risk_list = []\n",
    "\n",
    "for i in range(events_resimulate):\n",
    "    interp_mean = pd.read_csv(folder + str(i) + '/XX_mean.csv').rename(columns = {'x': 'Total'}) * (max_cons - min_cons) + min_cons\n",
    "    interp_95 = pd.read_csv(folder + str(i) + '/XX_95.csv').rename(columns = {'x': 'Total'}) * (max_cons - min_cons) + min_cons\n",
    "    interp_5 = pd.read_csv(folder + str(i) + '/XX_5.csv').rename(columns = {'x': 'Total'}) * (max_cons - min_cons) + min_cons\n",
    "\n",
    "    alm[i] = pd.read_csv(folder + str(i) + '/acqui.csv').mean().item()\n",
    "    rmse_arr[i] = RMSE(interp_mean.values, twod_training_target.values)\n",
    "\n",
    "    ead_tgp, risk_tgp = sam_util.obtain_cons(interp_mean.values, ex_rate = ex_rate)\n",
    "    ead_tgp_95, _ = sam_util.obtain_cons(interp_95.values, ex_rate = ex_rate)\n",
    "    ead_tgp_5, _ = sam_util.obtain_cons(interp_5.values, ex_rate = ex_rate)\n",
    "\n",
    "    ks_test = scipy.stats.ks_2samp(risk_tgp.iloc[:, 0].values, risk_ground.iloc[:, 0].values, method = 'asymp')\n",
    "    ead[i] = ead_tgp\n",
    "    ks[i] = ks_test.pvalue\n",
    "    risk_list.append(risk_tgp.iloc[:, 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_plot(model, ground, model_lab, c = 'b', ax = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.plot(ecdf(model)[0], ecdf(model)[1], c = c, label = model_lab)\n",
    "    ax.plot(ecdf(ground.iloc[:, 0].values)[0], ecdf(ground.iloc[:, 0].values)[1], c = '#ff7f0e', label = 'Benchmark')\n",
    "    start = np.array([model.min(), ground.iloc[:, 0].values.min()]).min()\n",
    "    ind_stop_2 = np.where(ecdf(model)[1] > 0.99)[0][0]\n",
    "    ind_stop_3 = np.where(ecdf(ground.iloc[:, 0].values)[1] > 0.99)[0][0]\n",
    "    end = np.array([model[len(model) - ind_stop_2], ground.iloc[:, 0].values[len(ground) - ind_stop_3]]).min()\n",
    "\n",
    "    ax.set_xlim([start, end])\n",
    "    ax.set_xlabel('Total damages [USD]', fontsize = 12)\n",
    "    ax.set_ylabel('Cumulative probability [-]', fontsize = 12)\n",
    "    ks_test = scipy.stats.ks_2samp(model, ground.iloc[:, 0].values, method = 'asymp')\n",
    "    ax.axvline(ks_test.statistic_location, ls = ':', c = 'k', label = f'Statistic location (result: {ks_test.statistic:.2f})')\n",
    "    ax.legend(fontsize = 12)\n",
    "    ax.text(0.2e8, 0.98, f\"KS p-value = {ks_test.pvalue:.2f}\", ha='left', va='bottom', fontsize = 12)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use.create_empty_folder('Figures/Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax_scaled = norm.normalize_dataset(df_two, scaler)\n",
    "\n",
    "corner_combinations = list(itertools.product([0, 1], repeat=df_two.shape[1]))\n",
    "df_grid = pd.DataFrame(corner_combinations, columns=df_minmax_scaled.columns)\n",
    "\n",
    "seed = df_minmax_scaled['S Mag'].argmax()\n",
    "\n",
    "mda_runs = 8**df_two.shape[1] - 2**df_two.shape[1]\n",
    "\n",
    "maxmin_class = selector_mda.MaxMin()\n",
    "lst_ind = maxmin_class.select_from_cluster(df_minmax_scaled.values, mda_runs, seed)\n",
    "subset = df_minmax_scaled.iloc[lst_ind].copy(deep = True)\n",
    "\n",
    "scaled_sims = pd.concat((df_grid, subset)).reset_index(drop = True)\n",
    "\n",
    "denorm_sims = norm.denormalize_dataset(scaled_sims, scaler).values\n",
    "denorm_sims = pd.DataFrame(denorm_sims, columns = df_two.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('Models/MDA_2d/damages.csv', index_col = 0)\n",
    "current_sampled = denorm_sims.copy(deep = True)\n",
    "current_sampled['Total'] = target[:len(denorm_sims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_current = np.zeros(len(denorm_sims) - mda_corners)\n",
    "risk_list_2 = []\n",
    "num_var = sampled_events.shape[1] - 1\n",
    "\n",
    "for i in range(len(denorm_sims) - mda_corners):\n",
    "    interp_target = griddata(current_sampled.iloc[:(mda_corners + i), :num_var], current_sampled.iloc[:(mda_corners + i), num_var], test_set.values, method='linear')\n",
    "    rmse_current[i] = RMSE(interp_target, twod_training_target.values)\n",
    "    ead_mda, risk_mda = sam_util.obtain_cons(interp_target, ex_rate = ex_rate)\n",
    "    ks_test = scipy.stats.ks_2samp(risk_mda.iloc[:, 0].values, risk_ground.iloc[:, 0].values, method = 'asymp')\n",
    "    risk_list_2.append(risk_mda.iloc[:, 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kw = dict(width_ratios=[1, 1], height_ratios=[1, 1])\n",
    "fig, axd = plt.subplot_mosaic([['upper left', 'right'],\n",
    "                               ['lower left', 'right']],\n",
    "                              gridspec_kw=gs_kw, figsize=(10, 8),\n",
    "                              layout=\"constrained\")\n",
    "\n",
    "axd['upper left']\n",
    "\n",
    "_ = ks_plot(risk_list[-1], risk_ground, 'Active learning', ax = axd['upper left'])\n",
    "axd['upper left'].set_xlim([0, 1.8e8])\n",
    "axd['upper left'].set_xlabel('')\n",
    "_ = ks_plot(risk_list_2[-1], risk_ground, 'Equidistant sampling', c='r', ax = axd['lower left'])\n",
    "axd['lower left'].set_xlim([0, 1.8e8])\n",
    "\n",
    "axd['right'].bar(0, ead_ground, color = '#ff7f0e', label = 'Benchmark')\n",
    "axd['right'].bar(1, ead_tgp, color= 'b', label = 'Active learning')\n",
    "axd['right'].bar(2, ead_mda, color = 'r', label = 'Equidistant\\nsampling')\n",
    "axd['right'].grid()\n",
    "axd['right'].tick_params(\n",
    "    axis='x',\n",
    "    which='both',\n",
    "    bottom=False, \n",
    "    top=False,\n",
    "    labelbottom=False)\n",
    "axd['right'].set_ylabel('EAD [USD]', fontsize = 12)\n",
    "axd['right'].errorbar(1, ead_tgp, yerr=[[ead_tgp - ead_tgp_5], [ead_tgp_95 - ead_tgp]], fmt='none', ecolor='black', label = 'Active learning\\nuncertainty', capsize = 5)\n",
    "\n",
    "axd['right'].legend(fontsize = 12)\n",
    "\n",
    "labels = ['(a)', '(b)', '(c)']\n",
    "\n",
    "# Loop through each subplot and add the content from existing figures\n",
    "clock = 0\n",
    "for ax in [axd['upper left'], axd['lower left'], axd['right']]:\n",
    "    ax.text(0.025, 0.95, labels[clock], transform=ax.transAxes, fontsize=14, verticalalignment='top', zorder=2, fontweight='bold')\n",
    "    clock+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/PDF/f08.pdf', dpi=300, format='pdf', bbox_inches=\"tight\")\n",
    "plt.savefig('Figures/PNG/f08.png', format='png', bbox_inches=\"tight\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(mda_corners, current_sampled.shape[0]), rmse_current, label = 'Equidistant sampling', c = 'r')\n",
    "plt.plot(np.arange(mda_corners, sampled_events.shape[0] + 1), rmse_arr, label = 'Active learning', c = sam_util.color_dic(2))\n",
    "plt.xlabel('Simulations used by approach [-]', fontsize = 12)\n",
    "plt.ylabel('RMSE [USD]', fontsize = 12)\n",
    "plt.grid()\n",
    "plt.legend(fontsize = 12)\n",
    "plt.savefig('Figures/PDF/f02.pdf', dpi=300, format='pdf', bbox_inches=\"tight\")\n",
    "plt.savefig('Figures/PNG/f02.png', format='png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_improv = np.abs(ead_mda - ead_ground)/np.abs(ead_ground - ead_tgp)\n",
    "print(f'EAD estimation improved by a factor: {factor_improv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_error = np.abs((ead_mda - ead_ground)) / ead_ground * 100\n",
    "print(f'EAD error for equidistant sampling: {mda_error:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgp_error = np.abs((ead_tgp - ead_ground)) / ead_ground * 100\n",
    "print(f'EAD error for active learning: {tgp_error:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_tgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_loss = np.abs(rmse_current[-1])/np.abs(rmse_arr[-1])\n",
    "print(f'RMSE loss improved by a factor: {factor_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Post RMSE: {rmse_arr[-1]/1e6} Million USD')\n",
    "print(f'Prior RMSE: {rmse_current[-1]/1e6} Million USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_current.argmin() + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arr.argmin()+4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.read_csv('Models/MDA_2d/times.csv', index_col = 0)\n",
    "clock = len(times[times[times.columns[0]] != 0])\n",
    "times = times.iloc[:clock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.sum().sum()/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgp_folder = 'Notebooks/4.Active_learning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_comp_single, samples_req_single = post.collect_tgp_times(tgp_folder)\n",
    "samples_req_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_comp_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_comp_single.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_comp = diff_comp_single[['A Posteriori (2 dims)']].copy(deep = True)\n",
    "single_comp.rename(columns = {'A Posteriori (2 dims)': 'Active learning'}, inplace = True)\n",
    "single_comp.loc[:, 'Equidistant sampling'] = times.sum()/60\n",
    "col_ind = [1, 0]\n",
    "post.plot_times(single_comp.iloc[:, col_ind])\n",
    "plt.savefig('Figures/PDF/f03.pdf', dpi=300, format='pdf', bbox_inches=\"tight\")\n",
    "plt.savefig('Figures/PNG/f03.png', format='png', bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
