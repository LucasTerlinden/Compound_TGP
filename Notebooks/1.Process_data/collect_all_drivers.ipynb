{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel: stat_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running in vs code\n",
    "# %cd ..\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 32.75\n",
    "long = -79.75 + 360\n",
    "\n",
    "df_u10 = pd.read_csv('Data/raw_data/u10_era5.csv')\n",
    "df_v10 = pd.read_csv('Data/raw_data/v10_era5.csv')\n",
    "df_msl = pd.read_csv('Data/raw_data/msl_era5.csv')\n",
    "df_tp = pd.read_csv('Data/raw_data/tp_era5.csv')\n",
    "df_met = pd.read_csv('Data/raw_data/Charleston_meteo.csv')\n",
    "df_wl = pd.read_csv('Data/raw_data/Charleston_waterlevel.csv')\n",
    "df_dis = pd.read_csv('Data/raw_data/USGS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_timezone(df, local, UTC, variable):\n",
    "    '''\n",
    "    Make time column a datetime, ensure time zone is UTC and set as index.\n",
    "    Ambiguous and nonexistant times are set to Not a Time.\n",
    "    Only returns a dataseries with variable and datetime as index at hourly intervals\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    variable: list of str or str\n",
    "        Column name(s) to be indexed\n",
    "    '''\n",
    "    df = df.rename(columns={df.columns[0]: f'DateTime({UTC})'})\n",
    "    df = df.set_index(pd.to_datetime(df.iloc[:, 0])) # time column should be the first column\n",
    "    df = df.loc[:, variable]\n",
    "    df = df.resample('h', origin = 'start').max() # resample to hourly and retain max\n",
    "    df.index = df.index.tz_localize(\n",
    "        local, ambiguous= 'NaT', nonexistent='NaT').tz_convert(UTC)\n",
    "    # Remove duplicate rows based on the index\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# era 5 timezones are utc\n",
    "df_u10 = set_timezone(df_u10, \"UTC\", \"UTC\", \"u10\")\n",
    "df_u10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v10 = set_timezone(df_v10, \"UTC\", \"UTC\", \"v10\")\n",
    "df_v10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp = set_timezone(df_tp, \"UTC\", \"UTC\", \"tp\") * 1000 # m / time step to mm / timestep\n",
    "df_tp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msl = set_timezone(df_msl, \"UTC\", \"UTC\", \"msl\")\n",
    "df_msl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dis = set_timezone(df_dis, \"US/Eastern\", \"UTC\", \"Discharge (metric)\")\n",
    "df_dis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl = set_timezone(df_wl, \"US/Eastern\", \"UTC\", [df_wl.columns[-2], df_wl.columns[-1]])\n",
    "df_wl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying 1 year mean moving average to non tidal residual to remove trend in mean sea level. Applying it to the NTR prevents averaging out longer tidal cycles that can occur with a period that is longer than a year. This average is then remove from the total water level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_coincide = df_wl.dropna().loc['1922':'2023']\n",
    "non_tidal_res = wl_coincide.iloc[:, 0] - wl_coincide.iloc[:, 1]\n",
    "mov_year = non_tidal_res.rolling(24*365, min_periods = 24*7*4*6).mean()\n",
    "mov_year.plot()\n",
    "plt.title('One Year Moving Average of Non-Tidal Residual')\n",
    "plt.ylabel('Watler Level [m]')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_coincide['WL_detrended (m)'] = wl_coincide.iloc[:, 0] - mov_year\n",
    "wl_coincide['WL_trend (m)'] = mov_year\n",
    "wl_coincide.head() # NaN's because minimum period to perform the moving average is six months. Not a problem as no other data available in 1922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met = set_timezone(df_met, \"US/Eastern\", \"UTC\", [\n",
    "                                                    df_met.columns[-3],\n",
    "                                                    df_met.columns[-2],\n",
    "                                                    df_met.columns[-1]\n",
    "                                                    ])\n",
    "df_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = df_met[df_met.columns[-1]].values\n",
    "direc = np.pi/180 * (df_met[df_met.columns[-2]].values - 180) # convert so that direction is now \"to\" not \"from\"\n",
    "u_x = mag * np.sin(direc)\n",
    "u_y = mag * np.cos(direc)\n",
    "df_met['u10'] = u_x\n",
    "df_met['v10'] = u_y\n",
    "df_met['msl'] = df_met[df_met.columns[-3]].values * 100 # convert mb to pa for pressure\n",
    "df_noaa_met = df_met['2022-01-01':].loc[:, ['u10', 'v10', 'msl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era_2021 = pd.concat([df_u10, df_v10, df_msl], \n",
    "    axis = 1, ignore_index = False)[:'2021-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extend time record by 2 years append data gathered by NOAA at Charleston gauge\n",
    "df_merged_met = pd.concat([df_era_2021, df_noaa_met], axis=0)\n",
    "df_merged_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = []\n",
    "for col in wl_coincide.columns:\n",
    "    par = col.find('(')\n",
    "    par_2 = col.find(')')\n",
    "    datum.append('(' + col[par+1:par_2] + ')')\n",
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_merged_met, df_tp, df_dis, wl_coincide],\n",
    "    axis = 1, ignore_index = False).rename(columns={'u10': 'hor_wind (m/s)',\n",
    "                                                    'v10': 'ver_wind (m/s)',\n",
    "                                                    'msl': 'Pressure (pa)',\n",
    "                                                    'tp': 'Precipitation (mm/hr)',\n",
    "                                                    'Discharge (metric)': 'Q (m^3/s)',\n",
    "                                                    wl_coincide.columns[0]: 'WL ' + datum[0],\n",
    "                                                    wl_coincide.columns[1]: 'Tidal (m)',\n",
    "                                                    wl_coincide.columns[2]: 'WL_detrend (m)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index().sort_values(by = 'DateTime(UTC)')\n",
    "df_all = df_all.set_index((df_all.iloc[:, 0])).drop(columns = 'DateTime(UTC)')\n",
    "# high limit, because discharge is missing data in 2001!\n",
    "# remove constant discharge at start of record\n",
    "df_record = df_all.bfill(limit = 365 * 24).dropna().iloc[364 * 24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = df_record.index.to_series().diff()[1:]\n",
    "indices_with_non_hourly_delta = diffs[diffs != pd.Timedelta(hours=1)].index\n",
    "if len(indices_with_non_hourly_delta) != 0:\n",
    "    print(indices_with_non_hourly_delta)\n",
    "    raise Exception('Missing data, check limit when filling in NaN values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcorded to ensure that there the number of days in the record is an integer\n",
    "df_record = df_record.iloc[2:]\n",
    "df_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove MMSL which could be caused by atmospheric pattern on a monthly-yearly scale, skewing durations and magnitudes of skew surge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df_record.index.year.unique()\n",
    "months = np.arange(1, 13, 1)\n",
    "mmsl_array = np.zeros((len(years), len(months)))\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        try:\n",
    "            wl_month_i = df_record.loc[str(year) + '-' + str(month), 'WL_detrend (m)'].copy()\n",
    "            mmsl = wl_month_i.mean()\n",
    "            mmsl_array[year - years[0], month - 1] = mmsl\n",
    "            df_record.loc[str(year) + '-' + str(month), 'WL_detrend_nommsl (m)'] = wl_month_i.values - mmsl\n",
    "        except KeyError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(mmsl_array)\n",
    "plt.title('Seasonality in Sea Level Throughout the Year')\n",
    "plt.xlabel('Months of the Year')\n",
    "plt.ylabel('Monthly Mean Sea Level [m]')\n",
    "label = ['Jan', 'Feb', 'Mar',\n",
    "         'Apr', 'May', 'Jun',\n",
    "         'Jul', 'Aug', 'Sep',\n",
    "         'Oct', 'Nov', 'Dec']\n",
    "plt.xticks(months, label)\n",
    "plt.ylim([-0.3, 0.3])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidal cycle defined as trough to trough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "\n",
    "troughs = argrelextrema(df_record['Tidal (m)'].values, np.less)\n",
    "troughs = troughs[0]\n",
    "troughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_surge_list = []\n",
    "peak_tides = []\n",
    "tidal_seasonal = df_record['Tidal (m)']\n",
    "\n",
    "under_1 = 0\n",
    "for i in range(len(troughs) + 1):\n",
    "    if i != len(troughs):\n",
    "        under_2 = troughs[i]\n",
    "    else:\n",
    "        under_2 = -1\n",
    "       \n",
    "    tidal_cycle_surge = df_record.iloc[under_1:under_2, [-4, -3]]\n",
    "    peak_tide = tidal_cycle_surge.iloc[:, 0].values.max()\n",
    "    peak_wl = tidal_cycle_surge.iloc[:, 1].values.max()\n",
    "    skew_surge = peak_wl - peak_tide\n",
    "    skew_surge_list.append(skew_surge)\n",
    "    \n",
    "    peak_tide = tidal_seasonal.iloc[under_1:under_2].values.max()\n",
    "    peak_tides.append(peak_tide)\n",
    "    \n",
    "    under_1 = under_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record['Skew_surge (m)'] = np.nan\n",
    "df_record.iloc[troughs, -1] = skew_surge_list[1:]\n",
    "df_record.iloc[0, -1] = skew_surge_list[0]\n",
    "df_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record.to_csv('Data/all_drivers.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl_ss = df_record.copy()\n",
    "col_names = df_wl_ss.columns\n",
    "df_wl_ss.drop(columns = [col_names[0], col_names[1], col_names[2], col_names[4], col_names[5]], inplace = True)\n",
    "df_wl_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_peaks = df_wl_ss['Skew_surge (m)'].dropna().to_frame()\n",
    "tidal_peaks['High Tide'] = peak_tides\n",
    "tidal_peaks['Diff'] = np.insert(np.diff(tidal_peaks.loc[:, 'High Tide']), 0, np.nan)\n",
    "if tidal_peaks['Diff'].iloc[1] > 0:\n",
    "    base = 'LH'\n",
    "    other = 'HH'\n",
    "else:\n",
    "    base = 'HH'\n",
    "    other = 'LH'\n",
    "tidal_peaks['Type'] = base\n",
    "tidal_peaks.loc[tidal_peaks['Diff'] > 0, 'Type'] = other\n",
    "\n",
    "tidal_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_peaks.to_csv('Data/skew_surge_tides.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
