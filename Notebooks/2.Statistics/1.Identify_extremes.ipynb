{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running in vs code\n",
    "# %cd ..\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel: stat_compound\n",
    "Notebook is used to identify extremes and define the skew surge and precipitation marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import hydromt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from fitter import Fitter\n",
    "%matplotlib inline\n",
    "\n",
    "import Notebooks.Scripts.statistics_helper as stats_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.read_csv('Data/all_drivers.csv')\n",
    "df_comp = df_comp.set_index(pd.to_datetime(df_comp.iloc[:, 0]))\n",
    "df_comp = df_comp.drop(columns = 'DateTime(UTC)')\n",
    "\n",
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl_ss = df_comp.copy()\n",
    "df_wl_ss.drop(columns = [df_comp.columns[0], df_comp.columns[1], df_comp.columns[2], df_comp.columns[4], df_comp.columns[5]], inplace = True)\n",
    "df_wl_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_peaks = pd.read_csv('Data/skew_surge_tides.csv', parse_dates = ['DateTime(UTC)'])\n",
    "tidal_peaks.set_index('DateTime(UTC)', inplace = True)\n",
    "tidal_peaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_hh = tidal_peaks[tidal_peaks['Type'] == 'HH']\n",
    "df_ss = cond_hh.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Selction\n",
    "The purpose of doing a peak over threshold analysis is to not only have more representative extremes but also to ensure i.i.d. draws (block maxima only retrieves the maxima within its block, if this year was relatively calm, an non extreme event may be retrieved. Also, since there is no declustering time, two extremes could be correlated to one another if they occur at the end of a block and the start of the next consecutive block). A brute force approach will be used to ensure an extreme rate of at least one: Starting at the highest threshold value identified by the mean residual life and parameter stability plot will be slowly decreased until > 1.0 peaks per year on average are obtained. To be conservative, the declustering time was set to two weeks.\n",
    "\n",
    "AIC vs AICc vs BIC. BIC is a baysian approach which prevents overfitting. Benefitial when there is little data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skew Surge with MMSL (use pyextremes python package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_help.POT_threshold_plots(df_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_help.threshold_stable(df_ss, 100, [0.3, 0.45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_extremes, ss_quantile, ss_threshold = stats_help.POT_brute_force(df_ss, 0.32, decluster=2*7) # assumes 1 tidal period per day, df_ss is every tidal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('fitted_stats/extreme_rate.txt', [ss_extremes['extremes_rate'].values.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_help.plot_extremes(df_ss, ss_extremes,\n",
    "                         threshold = ss_quantile, ev_type = 'POT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_help.plot_fits(df_ss, ss_extremes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_marginal = ss_extremes['peaks'].to_dataframe()['peaks'].dropna()\n",
    "ss_marginal.index = ss_marginal.index + np.timedelta64(6, 'h') # correct because of definition of skew surge (trough - trough)\n",
    "ss_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 24*3 # 3 days\n",
    "\n",
    "window_s = stats_help.find_largest_within_window('Skew_surge (m)', ss_marginal, df_wl_ss['Precipitation (mm/hr)'], 12, window_size)\n",
    "window_s['time_Skew_surge (m)'] = window_s['time_Skew_surge (m)'] - np.timedelta64(6, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_s.to_csv('fitted_stats/compound_given_ss.csv', index = False) # Identified historical compound events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save marginals for skew surge and precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_func = window_s.iloc[:, 2].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "distributions = [name for name in dir(scipy.stats) if isinstance(getattr(scipy.stats, name), scipy.stats.rv_continuous) or isinstance(getattr(scipy.stats, name), scipy.stats.rv_discrete)]\n",
    "\n",
    "sens_dist = []\n",
    "ignore = ['vonmises', 'uniform', 'wrapcauchy', 'bradford', 'argus',\n",
    "          'arcsine', 'ksone', 'triang', 'powerlaw', 'truncexpon',\n",
    "          'skewcauchy', 'wald', 'truncweibull_min', 'gibrat',\n",
    "          'trapz', 'trapezoid', 'kappa4', 'truncpareto', 'anglit'] # trunc does not extrapolate, others dont make sense to fit\n",
    "for dist in distributions:\n",
    "    if dist not in ignore:\n",
    "        sens_dist.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_curves = Fitter(bi_func, distributions=sens_dist, bins = 15)\n",
    "precip_curves.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "precip_curves.summary(method = 'bic')\n",
    "plt.xlabel('Precipitation Magnitude [mm/hr]')\n",
    "plt.ylabel('Density [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precipitation fit performs well on the non extreme events, but underestimates the probability of the extreme events. Visually, the lowest ks_statistic does not represent the emperical distribution the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mag_marg = precip_curves.get_best('bic')\n",
    "p_mag_marg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_help.save_marginal('fitted_stats/precipitation.json', p_mag_marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dis = ss_extremes['distribution'].data.item()\n",
    "param_names = ss_extremes['dparams'].data\n",
    "param_values = ss_extremes['parameters'].data\n",
    "\n",
    "ss_dic = stats_help.create_nested_dict(name_dis, param_names, param_values)\n",
    "ss_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_help.save_marginal('fitted_stats/skew_surge.json', ss_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
